# Day3 学习日志

今天主要完成了以下内容：

1. 网络爬虫实践
- task1.py：使用 requests 和 BeautifulSoup 爬取豆瓣电影一周口碑榜，提取Top10电影名称及评分，并保存网页源码。
- task2.py：用 requests 和 lxml 爬取图片网站首页图片，批量下载并保存到本地 data 目录。
- task3.py：利用 selenium、fake_useragent 等库，自动化爬取谷歌学术文献，模拟人类操作防止被反爬，批量检索文献标题并保存结果。

2. 数据分析与处理
- task4.py：分析 drinks.csv 数据，统计各大洲啤酒、红酒、烈酒的平均消耗量及描述性统计，掌握了 pandas 分组聚合和统计方法。
- task5.py：合并2015-2017年国内主要城市年度数据，处理缺失值，统计各年国内生产总值，并将结果保存为新CSV。
- task6.py：练习了缺失值处理，创建带空值的学生成绩表，填充缺失数据并保存清洗后的结果。

3. 数据可视化
- task7.py：用 matplotlib 绘制 y=x³ 曲线，并模拟生成随机日期和销量数据，绘制销售趋势图。

收获与反思：
- 熟悉了 requests、BeautifulSoup、lxml、selenium 等常用爬虫工具的用法。
- 掌握了 pandas 的数据清洗、分组、聚合、缺失值处理等常用操作。
- 提升了数据可视化能力，能用 matplotlib 绘制多种图形。
- 体会到自动化和数据处理在实际项目中的重要性。

后续计划：
- 深入学习数据分析与可视化高级技巧。
- 尝试将爬取的数据与分析结果结合，做成小型数据项目。

